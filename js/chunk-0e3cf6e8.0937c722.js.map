{"version":3,"sources":["webpack:///./src/views/BBTFaceRecognition.vue?f01a","webpack:///src/views/BBTFaceRecognition.vue","webpack:///./src/views/BBTFaceRecognition.vue?9d17","webpack:///./src/views/BBTFaceRecognition.vue","webpack:///./src/views/BBTFaceRecognition.vue?942b"],"names":["render","_vm","this","_h","$createElement","_c","_self","staticClass","_v","attrs","on","$event","fnChange","directives","name","rawName","value","expression","domProps","_q","nets","_m","_l","item","i","key","staticStyle","_s","img","staticRenderFns","data","options","sampleArr","faceMatcher","imgEl","canvasEl","watch","val","fnInit","then","mounted","$nextTick","methods","e","target","files","length","component"],"mappings":"yHAAA,IAAIA,EAAS,WAAa,IAAIC,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,4BAA4B,CAACF,EAAG,MAAM,CAACE,YAAY,UAAU,CAACF,EAAG,MAAM,CAACA,EAAG,QAAQ,CAACJ,EAAIO,GAAG,YAAYH,EAAG,QAAQ,CAACI,MAAM,CAAC,KAAO,OAAO,OAAS,yBAAyBC,GAAG,CAAC,OAAS,SAASC,GAAQ,OAAOV,EAAIW,SAASD,SAAcN,EAAG,MAAM,CAACA,EAAG,QAAQ,CAACJ,EAAIO,GAAG,YAAYH,EAAG,QAAQ,CAACJ,EAAIO,GAAG,oBAAoBH,EAAG,QAAQ,CAACQ,WAAW,CAAC,CAACC,KAAK,QAAQC,QAAQ,UAAUC,MAAOf,EAAQ,KAAEgB,WAAW,SAASR,MAAM,CAAC,KAAO,QAAQ,MAAQ,kBAAkBS,SAAS,CAAC,QAAUjB,EAAIkB,GAAGlB,EAAImB,KAAK,mBAAmBV,GAAG,CAAC,OAAS,SAASC,GAAQV,EAAImB,KAAK,uBAAuBf,EAAG,QAAQ,CAACJ,EAAIO,GAAG,sBAAsBH,EAAG,QAAQ,CAACQ,WAAW,CAAC,CAACC,KAAK,QAAQC,QAAQ,UAAUC,MAAOf,EAAQ,KAAEgB,WAAW,SAASR,MAAM,CAAC,KAAO,QAAQ,MAAQ,oBAAoBS,SAAS,CAAC,QAAUjB,EAAIkB,GAAGlB,EAAImB,KAAK,qBAAqBV,GAAG,CAAC,OAAS,SAASC,GAAQV,EAAImB,KAAK,yBAAyBf,EAAG,QAAQ,CAACJ,EAAIO,GAAG,WAAWH,EAAG,QAAQ,CAACQ,WAAW,CAAC,CAACC,KAAK,QAAQC,QAAQ,UAAUC,MAAOf,EAAQ,KAAEgB,WAAW,SAASR,MAAM,CAAC,KAAO,QAAQ,MAAQ,SAASS,SAAS,CAAC,QAAUjB,EAAIkB,GAAGlB,EAAImB,KAAK,UAAUV,GAAG,CAAC,OAAS,SAASC,GAAQV,EAAImB,KAAK,kBAAkBf,EAAG,KAAK,CAACJ,EAAIO,GAAG,UAAUP,EAAIoB,GAAG,GAAGhB,EAAG,KAAK,CAACJ,EAAIO,GAAG,UAAUP,EAAIqB,GAAIrB,EAAa,WAAE,SAASsB,EAAKC,GAAG,OAAOnB,EAAG,MAAM,CAACoB,IAAID,GAAG,CAACnB,EAAG,OAAO,CAACqB,YAAY,CAAC,MAAQ,WAAWR,SAAS,CAAC,YAAcjB,EAAI0B,GAAGJ,EAAKT,SAAST,EAAG,MAAM,CAACE,YAAY,OAAON,EAAIqB,GAAIC,EAAQ,KAAE,SAASK,GAAK,OAAOvB,EAAG,MAAM,CAACoB,IAAIG,EAAInB,MAAM,CAAC,IAAMmB,EAAI,IAAML,EAAKT,WAAU,SAAQ,IACnkDe,EAAkB,CAAC,WAAa,IAAI5B,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,UAAU,CAACF,EAAG,MAAM,CAACI,MAAM,CAAC,GAAK,YAAY,IAAM,0BAA0BJ,EAAG,SAAS,CAACI,MAAM,CAAC,GAAK,sB,kIC2CtO,GACEK,KAAM,qBACNgB,KAFF,WAGI,MAAO,CACLV,KAAM,iBACNW,QAAS,KAETC,UAAW,CACjB,CACQ,KAAR,MACQ,IAAR,CACA,4BACA,4BACA,4BACA,8BAGA,CACQ,KAAR,OACQ,IAAR,CACA,8BACA,8BACA,8BACA,iCAKMC,YAAa,KACbC,MAAO,KACPC,SAAU,OAGdC,MAAO,CACLhB,KADJ,SACA,cACMlB,KAAKkB,KAAOiB,EACZnC,KAAKoC,SAASC,MAAK,WAAzB,sBAGEC,QAvCF,WAuCA,WACItC,KAAKuC,WAAU,WACb,EAAN,kDAGEC,QAAS,CAEP,OAFJ,WAEA,wKACA,yCADA,uBAEA,sCAFA,uBAGA,yCAHA,YAKA,OALA,OAMA,mBANA,OAWA,qBAXA,QAiBA,UAjBA,+BAOA,0CACA,mBARA,oCAYA,4CACA,cACA,oBAdA,oCAkBA,iCACA,eACA,mBApBA,oCAyBA,6CACA,mDA1BA,UA2BA,kBA3BA,+CA8BI,cAhCJ,WAgCA,8KACA,YACA,sLAEA,KAFA,iBAGA,OAHA,gEAGA,EAHA,iBAIA,mBAJA,cAIA,EAJA,YAKA,EALA,UAKA,8BALA,yBAKA,KALA,2LAQA,2CARA,wHAFA,OACA,EADA,OAcA,sCAdA,8CAiBI,MAjDJ,WAiDA,gLACA,oBACA,mBACA,oBACA,sBAJA,OACA,EADA,OAKA,yCACA,gCACA,wDACA,4CACA,2DATA,8CAaI9B,SA9DJ,SA8DA,cACW+B,EAAEC,OAAOC,MAAMC,QAEpB,EAAN,sDACQ,EAAR,gBACQ,EAAR,SACA,iBACA,kDACQ,EAAR,cC9J4V,I,wBCQxVC,EAAY,eACd,EACA/C,EACA6B,GACA,EACA,KACA,WACA,MAIa,aAAAkB,E,kECnBf,yBAAif,EAAG","file":"js/chunk-0e3cf6e8.0937c722.js","sourcesContent":["var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"face_recognition_library\"},[_c('div',{staticClass:\"option\"},[_c('div',[_c('label',[_vm._v(\"匹配图选择：\")]),_c('input',{attrs:{\"type\":\"file\",\"accept\":\"image/png, image/jpeg\"},on:{\"change\":function($event){return _vm.fnChange($event)}}})]),_c('div',[_c('label',[_vm._v(\"选择算法模型\")]),_c('label',[_vm._v(\" ssdMobilenetv1 \"),_c('input',{directives:[{name:\"model\",rawName:\"v-model\",value:(_vm.nets),expression:\"nets\"}],attrs:{\"type\":\"radio\",\"value\":\"ssdMobilenetv1\"},domProps:{\"checked\":_vm._q(_vm.nets,\"ssdMobilenetv1\")},on:{\"change\":function($event){_vm.nets=\"ssdMobilenetv1\"}}})]),_c('label',[_vm._v(\" tinyFaceDetector \"),_c('input',{directives:[{name:\"model\",rawName:\"v-model\",value:(_vm.nets),expression:\"nets\"}],attrs:{\"type\":\"radio\",\"value\":\"tinyFaceDetector\"},domProps:{\"checked\":_vm._q(_vm.nets,\"tinyFaceDetector\")},on:{\"change\":function($event){_vm.nets=\"tinyFaceDetector\"}}})]),_c('label',[_vm._v(\" mtcnn \"),_c('input',{directives:[{name:\"model\",rawName:\"v-model\",value:(_vm.nets),expression:\"nets\"}],attrs:{\"type\":\"radio\",\"value\":\"mtcnn\"},domProps:{\"checked\":_vm._q(_vm.nets,\"mtcnn\")},on:{\"change\":function($event){_vm.nets=\"mtcnn\"}}})])])]),_c('h3',[_vm._v(\"匹配图：\")]),_vm._m(0),_c('h3',[_vm._v(\"样本库：\")]),_vm._l((_vm.sampleArr),function(item,i){return _c('div',{key:i},[_c('span',{staticStyle:{\"color\":\"#42b983\"},domProps:{\"textContent\":_vm._s(item.name)}}),_c('div',{staticClass:\"pic\"},_vm._l((item.img),function(img){return _c('img',{key:img,attrs:{\"src\":img,\"alt\":item.name}})}),0)])})],2)}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"target\"},[_c('img',{attrs:{\"id\":\"targetImg\",\"src\":\"images/xxm/xxm03.jpg\"}}),_c('canvas',{attrs:{\"id\":\"targetCanvas\"}})])}]\n\nexport { render, staticRenderFns }","<template>\r\n  <div class=\"face_recognition_library\">\r\n    <div class=\"option\">\r\n      <div>\r\n        <label>匹配图选择：</label>\r\n        <input\r\n          type=\"file\"\r\n          accept=\"image/png, image/jpeg\"\r\n          @change=\"fnChange($event)\"\r\n        />\r\n      </div>\r\n      <div>\r\n        <label>选择算法模型</label>\r\n        <label>\r\n          ssdMobilenetv1\r\n          <input type=\"radio\" v-model=\"nets\" value=\"ssdMobilenetv1\" />\r\n        </label>\r\n        <label>\r\n          tinyFaceDetector\r\n          <input type=\"radio\" v-model=\"nets\" value=\"tinyFaceDetector\" />\r\n        </label>\r\n        <label>\r\n          mtcnn\r\n          <input type=\"radio\" v-model=\"nets\" value=\"mtcnn\" />\r\n        </label>\r\n      </div>\r\n    </div>\r\n    <h3>匹配图：</h3>\r\n    <div class=\"target\">\r\n      <img id=\"targetImg\" src=\"images/xxm/xxm03.jpg\" />\r\n      <canvas id=\"targetCanvas\" />\r\n    </div>\r\n    <h3>样本库：</h3>\r\n    <div v-for=\"(item, i) in sampleArr\" :key=\"i\">\r\n      <span style=\"color: #42b983;\" v-text=\"item.name\"></span>\r\n      <div class=\"pic\">\r\n        <img v-for=\"img in item.img\" :key=\"img\" :src=\"img\" :alt=\"item.name\" />\r\n      </div>\r\n    </div>\r\n  </div>\r\n</template>\r\n\r\n<script>\r\nimport * as faceapi from \"face-api.js\";\r\nexport default {\r\n  name: \"BBTFaceRecognition\",\r\n  data() {\r\n    return {\r\n      nets: \"ssdMobilenetv1\",\r\n      options: null,\r\n      // 预设样本图，支持本地，网络，beas64\r\n      sampleArr: [\r\n        {\r\n          name: \"欣小萌\",\r\n          img: [\r\n            \"images/xxm/face/xxm01.png\",\r\n            \"images/xxm/face/xxm02.png\",\r\n            \"images/xxm/face/xxm03.png\",\r\n            \"images/xxm/face/xxm04.png\",\r\n          ],\r\n        },\r\n        {\r\n          name: \"旭旭宝宝\",\r\n          img: [\r\n            \"images/xxbb/face/xxbb01.png\",\r\n            \"images/xxbb/face/xxbb02.png\",\r\n            \"images/xxbb/face/xxbb03.png\",\r\n            \"images/xxbb/face/xxbb04.png\",\r\n          ],\r\n        },\r\n      ],\r\n      // 样本人脸匹配矩阵数组对象转码结果\r\n      faceMatcher: null,\r\n      imgEl: null,\r\n      canvasEl: null,\r\n    };\r\n  },\r\n  watch: {\r\n    nets(val) {\r\n      this.nets = val;\r\n      this.fnInit().then(() => this.fnRun());\r\n    },\r\n  },\r\n  mounted() {\r\n    this.$nextTick(() => {\r\n      this.fnInit().then(() => this.fnRun());\r\n    });\r\n  },\r\n  methods: {\r\n    // 初始化模型加载\r\n    async fnInit() {\r\n      await faceapi.nets[this.nets].loadFromUri(\"/models\");\r\n      await faceapi.loadFaceLandmarkModel(\"/models\");\r\n      await faceapi.loadFaceRecognitionModel(\"/models\");\r\n      // 根据模型参数识别调整结果\r\n      switch (this.nets) {\r\n        case \"ssdMobilenetv1\":\r\n          this.options = new faceapi.SsdMobilenetv1Options({\r\n            minConfidence: 0.5, // 0.1 ~ 0.9\r\n          });\r\n          break;\r\n        case \"tinyFaceDetector\":\r\n          this.options = new faceapi.TinyFaceDetectorOptions({\r\n            inputSize: 512, // 160 224 320 416 512 608\r\n            scoreThreshold: 0.5, // 0.1 ~ 0.9\r\n          });\r\n          break;\r\n        case \"mtcnn\":\r\n          this.options = new faceapi.MtcnnOptions({\r\n            minFaceSize: 20, // 0.1 ~ 0.9\r\n            scaleFactor: 0.709, // 0.1 ~ 0.9\r\n          });\r\n          break;\r\n      }\r\n      // 节点对象\r\n      this.imgEl = document.getElementById(\"targetImg\");\r\n      this.canvasEl = document.getElementById(\"targetCanvas\");\r\n      await this.fnfaceMatcher();\r\n    },\r\n    // 生成人脸匹配矩阵数组对象，样本图片同步转码\r\n    async fnfaceMatcher() {\r\n      const labeledFaceDescriptors = await Promise.all(\r\n        this.sampleArr.map(async (item) => {\r\n          // 临时图片转码数据，将图片对象转数据矩阵对象\r\n          let descriptors = [];\r\n          for (let image of item.img) {\r\n            const imageEl = await faceapi.fetchImage(image);\r\n            descriptors.push(await faceapi.computeFaceDescriptor(imageEl));\r\n          }\r\n          // 返回图片用户和图片转码数组\r\n          return new faceapi.LabeledFaceDescriptors(item.name, descriptors);\r\n        })\r\n      );\r\n      // 人脸匹配矩阵数组对象转码结果\r\n      this.faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors);\r\n    },\r\n    // 执行识别匹配图片，数值误差越小越精确\r\n    async fnRun() {\r\n      const results = await faceapi\r\n        .detectAllFaces(this.imgEl, this.options)\r\n        .withFaceLandmarks()\r\n        .withFaceDescriptors();\r\n      faceapi.matchDimensions(this.canvasEl, this.imgEl);\r\n      const resizedResults = faceapi.resizeResults(results, this.imgEl);\r\n      resizedResults.forEach(({ detection, descriptor }) => {\r\n        const label = this.faceMatcher.findBestMatch(descriptor).toString();\r\n        new faceapi.draw.DrawBox(detection.box, { label }).draw(this.canvasEl);\r\n      });\r\n    },\r\n    // 更换匹配图\r\n    fnChange(e) {\r\n      if (!e.target.files.length) return;\r\n      // 将文件显示为图像并识别\r\n      faceapi.bufferToImage(e.target.files[0]).then((img) => {\r\n        this.imgEl.src = img.src;\r\n        this.canvasEl\r\n          .getContext(\"2d\")\r\n          .clearRect(0, 0, this.canvasEl.width, this.canvasEl.height);\r\n        this.fnRun();\r\n      });\r\n    },\r\n  },\r\n};\r\n</script>\r\n\r\n<style scoped>\r\n.target {\r\n  position: relative;\r\n}\r\n.target img {\r\n  max-width: 600px;\r\n  max-height: 400px;\r\n}\r\n.target canvas {\r\n  position: absolute;\r\n  top: 0;\r\n  left: 0;\r\n}\r\n.pic {\r\n  display: flex;\r\n  flex-direction: row;\r\n  flex-wrap: wrap;\r\n}\r\n.pic img {\r\n  max-width: 90px;\r\n  max-height: 90px;\r\n  margin: 10px;\r\n}\r\n.option {\r\n  padding-bottom: 20px;\r\n}\r\n.option div {\r\n  padding: 10px;\r\n  border-bottom: 2px #42b983 solid;\r\n}\r\n.option div label {\r\n  margin-right: 20px;\r\n}\r\n</style>\r\n","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./BBTFaceRecognition.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./BBTFaceRecognition.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./BBTFaceRecognition.vue?vue&type=template&id=75b53924&scoped=true&\"\nimport script from \"./BBTFaceRecognition.vue?vue&type=script&lang=js&\"\nexport * from \"./BBTFaceRecognition.vue?vue&type=script&lang=js&\"\nimport style0 from \"./BBTFaceRecognition.vue?vue&type=style&index=0&id=75b53924&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"75b53924\",\n  null\n  \n)\n\nexport default component.exports","import mod from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./BBTFaceRecognition.vue?vue&type=style&index=0&id=75b53924&scoped=true&lang=css&\"; export default mod; export * from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./BBTFaceRecognition.vue?vue&type=style&index=0&id=75b53924&scoped=true&lang=css&\""],"sourceRoot":""}